<!DOCTYPE html>
<html>
    <head>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-89797207-1"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'UA-89797207-1');
        </script>
        <title>Xinyi Zhang</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=1000">
        <link rel="stylesheet" href="https://use.typekit.net/quv7bsd.css"> <!-- fonts -->
        <link rel="stylesheet" href="style.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <!-- <link rel="stylesheet" href="http://andyzeng.github.io/style.css" /> -->
        
    </head>

    <body id="body">
        <div id="main"> 
            <ul>
                <li><a class="active" href="/index" style="font-size: 18px;font-weight: bold;margin-right: 70px">Xinyi Zhang</a></li>
                <li><a href="/publication">Publications</a></li>
                <li><a href="/biography">Biography</a></li>
                <li><a href="/resource">Resource</a></li>
            </ul>

            <div id="profile">
                <img src="images/myself.jpg">
                <div id="profile-name">Xinyi Zhang</div>
                <div id="profile-desc">
                    <p>
                        <a href="https://github.com/xinyizzzhang/" target="_blank" class="fa fa-github" style="font-size: 22px;margin-right: 10px;color:#a0a8b0"></a>
                        <a href="https://www.youtube.com/channel/UCgQHDoZ0UECEeL5-lSsRH8w" target="_blank" class="fa fa-youtube-play" style="font-size: 22px;margin-right: 10px;color:#a0a8b0"></a>
                    </p>
                    <p>
                        I'm a Ph.D. student at <a href="https://www.roboticmanipulation.org/">Harada Lab.</a> in <a href="https://www.osaka-u.ac.jp/en">Osaka University</a>, advised by <a href="http://www.hlab.sys.es.osaka-u.ac.jp/people/harada/">Professor Kensuke Harada</a>. My research interests include perception and planning for vision-based industrial picking under complex scenarios. I received my M.E. from Osaka University and B.E. from Tianjin University, China.
                    </p>
                    <p>
                        E-mail: chou [at] hlab.sys.es.osaka-u.ac.jp
                    </p>
                </div>
                <div style="clear: both;"></div>
            </div>

            <div class="section content">
                <h1>Research Topics</h1>

                <h2>Bin-picking strategies for complex physical phenomenon</h2>
                <p>
                    a. Grasp planning considering both entanglement and collision for a 2-jaw gripper
                    <br />b. Motion Generation for separating entangled partrs
                </p>
                <h2>Accuracy on vision-based bin-picking</h2>
                <p>
                    Online error compensation
                </p>
            </div>

            <div class="divider"></div>

            <div class="section research">
                <h1>Projects</h1>
                <div class="research-proj">
                    <a href="https://www.youtube.com/watch?v=BFTuQWeULyw&t=3s" class="research-thumb">
                        <video playsinline="" muted="" autoplay="" loop="" width="180px">
                            <source src="images/project_cable.mp4" type="video/mp4">
                        </video>
                    </a>
                    <div class="research-proj-desc">
                        <h2>Learning Effective and Sequential Policy for Picking Cable Harnesses</h2>
                        <p>
                            This paper introduces an autonomous bin picking system for cable harnesses - an extremely challenging object in bin picking task. Currently cable harnesses are unsuitable to be imported to automated production due to their length and elusive structures. Considering the task of robotic bin picking where the harnesses are heavily entangled, it is challenging for a robot to pick harnesses up one by one using conventional bin picking methods. In this paper, we present an efficient approach to overcoming the difficulties when dealing with entangled-prone parts. We develop several motion schemes for the robot to pick up a single harness avoiding any entanglement. Moreover, we proposed a learning-based bin picking policy to select both grasps and designed motion schemes in a reasonable sequence. Our method is unique due to the novelty for sufficiently solving the entanglement problem in picking cluttered cable harnesses. We demonstrate our approach on a set of real-world experiments, during which the proposed method is capable to perform the sequential bin picking task with both effectiveness and accuracy under a variety of cluttered scenarios.
                        </p>
                    </div>
                </div>
                <div class="research-proj">
                    <a class="research-thumb">
                        <img src="images/project-emap.jpg" alt="" width="180px">
                    </a>
                    <div class="research-proj-desc">
                        <h2>Detect Non-Tangled Grasps for Bin-picking</h2>
                        <p>
                            This paper addresses the problem of picking up only one object at a time avoiding any entanglement in bin-picking. To cope with a difficult case where the complex-shaped objects are heavily entangled together, we propose a topology-based method that can generate non-tangle grasp positions on a single depth image. The core technique is the entanglement map, which is a feature map to measure the entanglement possibilities obtained from the input image. We use an entanglement map to select probable regions containing graspable objects. The optimum grasping pose is detected from the selected regions considering the collision between robot hand and objects. Experimental results show that our analytic method provides a more comprehensive and intuitive observation of the entanglement and exceeds previous learning-based work in success rates. Especially, our topology-based method does not rely on any object models or time-consuming training process, so that it can be easily adapted to more complex bin-picking scenes.
                        </p>
                    </div>
                </div>
            </div>
            
            <div class="divider"></div>

            <div class="section content">
                <h1>Links</h1>
                <p><a href="https://www.youtube.com/watch?v=BFTuQWeULyw&t=3s" target="_blank">Harada Lab.</a></p>
                <p><a href="https://www.youtube.com/watch?v=BFTuQWeULyw&t=3s"target="_blank">Division of Systems Science and Applied Informatics</a></p>
                <p><a href="https://www.youtube.com/watch?v=BFTuQWeULyw&t=3s"target="_blank">Graduate School of Engineering Science</a></p>
                <p><a href="https://www.youtube.com/watch?v=BFTuQWeULyw&t=3s"target="_blank">Osaka University</a></p>
                
            </div>
        </div>
    </body>
</html>